---
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
rt <- readRDS(".readme.rds")
library(chr)
```

## chr

R package for simple string manipulation

*this package is in early development*

## Description

Clean, wrangle, and parse character [string] vectors using base exclusively base
R functions.

## Install

```{r install}
## install from github
if (!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("mkearney/chr")

## load chr
library(chr)
```

## Usage

`chr` offers lightweight functionality similar to
[`stringr`](https://github.com/tidyverse/stringr). For example, say you have
some text that needs taming, e.g., Twitter data:

```{r rtweet}
## get text to manipulate
rt <- rtweet::search_tweets("lang:en", n = 500)
```

### Extract

**Extract** text patterns.

```{r extract, eval = TRUE}
## some tweets with 'their', 'there', or 'they're'
rt$text[c(5, 9, 34, 76, 84, 157, 256)]

## extract all there/their/they're
chr_extract(
  rt$text[c(5, 9, 34, 76, 84, 157, 256)], 
  "there|their|they\\S?re", 
  ignore.case = TRUE
)

## do it again but return single-length values
chr_extract(
  rt$text[c(5, 9, 34, 76, 84, 157, 256)], 
  "there|their|they\\S?re", 
  ignore.case = TRUE, 
  collapse = "+"
)

## extract first there/their/they're
chr_extract_first(
  rt$text[c(5, 9, 34, 76, 84, 157, 256)], 
  "there|their|they\\S?re", 
  ignore.case = TRUE
)

## tweets with URL links
rt$text[1:3]

## extract all URLS
chr_extract_links(rt$text[1:3])

## tweet with hashtags
rt$text[78]

## extract all hashtags
chr_extract_hashtags(rt$text[c(40, 41, 77, 78)])

## tweet with and without mentions
rt$text[1:2]

## extract mentions
chr_extract_mentions(rt$text[1:2])
```

### Count

**Count** number of matches.

```{r count, eval = TRUE}
## extract all there/their/they're
chr_count(
  rt$text[c(5, 9, 34, 76, 84, 157, 256)], 
  "there|their|they\\S?re", 
  ignore.case = TRUE
)
```

### Remove

**Remove** text patterns.

```{r remove, eval = TRUE}
## remove URLS
chr_remove_links(rt$text[1:3])

## string together functions with magrittr pipe
library(magrittr)

## remove mentions and extra [white] spaces
chr_remove_mentions(rt$text[1:3]) %>% 
  chr_remove_ws()

## remove hashtags
chr_remove_hashtags(rt$text[78])

## remove hashtags, line breaks, and extra spaces
rt$text[78] %>%
  chr_remove_hashtags() %>%
  chr_remove_linebreaks() %>%
  chr_remove_ws()

## remove links and extract words
rt$text[1:3] %>%
  chr_remove_links() %>%
  chr_remove_mentions() %>%
  chr_extract_words()
```

### Detect

**Detect** text patterns.

```{r detect, eval = TRUE}
## extract all there/their/they're
chr_detect(
  rt$text[c(5, 9, 34, 76, 84, 157, 256)], 
  "there|their|they\\S?re", 
  ignore.case = TRUE
)
```


### Replace

**Replace** text with string.

```{r replace, eval = TRUE}
## some text
x <- c("Acme Pizza, Inc.", "Tom's Sports Equipment, LLC")

## replace acme with Kearney
chr_replace(x, "acme", "Kearney", ignore.case = TRUE)
```

ASCII functions currently *in progress*. For example, replace non-ASCII symbols
with similar ASCII characters (*work in progress*).

```{r ascii, eval = TRUE}
## compare before and after
Map(
  identical, chr_replace_nonascii(rt$text[c(1, 51, 57, 62)]), 
  rt$text[c(1, 51, 57, 62)], 
  USE.NAMES = FALSE
)

## original
rt$text[c(51, 57, 62)]

## ascii version
chr_replace_nonascii(rt$text[c(51, 57, 62)])
```


### n-grams

Create **ngram**s at the character.

```{r ngrams, eval = TRUE}
## character vector
x <- c("Acme Pizza, Inc.", "Tom's Sports Equipment, LLC")

## 2 char level ngram
chr_ngram_char(x, n = 2L)

## 3 char level ngram in lower case and stripped of punctation and white space
chr_ngram_char(x, n = 3L, lower = TRUE, punct = TRUE, space = TRUE)
```
